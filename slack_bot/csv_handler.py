"""
CSV export functionality for the Slack bot.
Handles creation and formatting of CSV files for data export.
"""
import logging
import tempfile
import os
from typing import List, Dict, Any, Tuple
from datetime import datetime
import pandas as pd
import re

logger = logging.getLogger(__name__)


class CSVHandler:
    """
    Handles CSV file generation and export functionality.
    
    Features:
    - Clean data formatting for CSV export
    - Proper column naming and ordering
    - File naming conventions
    - Temporary file management
    """
    
    def __init__(self):
        """Initialize the CSV handler."""
        self.temp_dir = tempfile.gettempdir()
    
    def _clean_filename(self, question: str) -> str:
        """
        Create a clean filename from a user question.
        
        Args:
            question: User's original question
            
        Returns:
            Cleaned filename suitable for file system
        """
        # Remove special characters and limit length
        clean_name = re.sub(r'[^\w\s-]', '', question)
        clean_name = re.sub(r'[-\s]+', '_', clean_name)
        clean_name = clean_name.strip('_').lower()
        
        # Limit length
        if len(clean_name) > 50:
            clean_name = clean_name[:50]
        
        # Add timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        return f"rounds_analytics_{clean_name}_{timestamp}.csv"
    
    def _format_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Format DataFrame for CSV export with proper column names and data types.
        
        Args:
            df: Raw DataFrame from query results
            
        Returns:
            Formatted DataFrame ready for CSV export
        """
        # Create a copy to avoid modifying original
        formatted_df = df.copy()
        
        # Clean column names
        formatted_df.columns = [
            col.replace('_', ' ').title() 
            for col in formatted_df.columns
        ]
        
        # Format specific data types
        for col in formatted_df.columns:
            col_lower = col.lower()
            
            # Format currency columns
            if any(keyword in col_lower for keyword in ['revenue', 'cost', 'price']):
                if formatted_df[col].dtype in ['int64', 'float64']:
                    formatted_df[col] = formatted_df[col].apply(
                        lambda x: f"${x:,.2f}" if pd.notna(x) else ""
                    )
            
            # Format large number columns (installs, downloads, etc.)
            elif any(keyword in col_lower for keyword in ['install', 'download', 'user', 'count']):
                if formatted_df[col].dtype in ['int64', 'float64']:
                    formatted_df[col] = formatted_df[col].apply(
                        lambda x: f"{int(x):,}" if pd.notna(x) else ""
                    )
            
            # Format percentage columns
            elif any(keyword in col_lower for keyword in ['rate', 'percent', 'ratio']):
                if formatted_df[col].dtype in ['int64', 'float64']:
                    formatted_df[col] = formatted_df[col].apply(
                        lambda x: f"{x:.2f}%" if pd.notna(x) else ""
                    )
            
            # Format date columns
            elif any(keyword in col_lower for keyword in ['date', 'time', 'created', 'updated']):
                try:
                    formatted_df[col] = pd.to_datetime(formatted_df[col]).dt.strftime('%Y-%m-%d')
                except (ValueError, TypeError):
                    pass  # Keep original format if conversion fails
            
            # Format decimal columns (keep 2 decimal places)
            elif formatted_df[col].dtype == 'float64':
                formatted_df[col] = formatted_df[col].apply(
                    lambda x: f"{x:.2f}" if pd.notna(x) else ""
                )
        
        return formatted_df
    
    def _add_metadata_sheet(self, writer: pd.ExcelWriter, question: str, 
                          sql_query: str, result_count: int):
        """
        Add metadata sheet to Excel export (future enhancement).
        
        Args:
            writer: Excel writer object
            question: Original user question
            sql_query: SQL query used
            result_count: Number of results
        """
        metadata = {
            'Export Information': [
                'Generated by Rounds Analytics Bot',
                f'Export Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}',
                f'Original Question: {question}',
                f'Number of Records: {result_count}',
                '',
                'SQL Query Used:',
                sql_query
            ]
        }
        
        metadata_df = pd.DataFrame(metadata)
        metadata_df.to_excel(writer, sheet_name='Export Info', index=False, header=False)
    
    async def create_csv_file(self, data: List[Dict[str, Any]], 
                            question: str, include_metadata: bool = True) -> Tuple[str, str]:
        """
        Create a CSV file from query results.
        
        Args:
            data: Query result data
            question: Original user question
            include_metadata: Whether to include metadata in the file
            
        Returns:
            Tuple of (file_path, filename)
        """
        try:
            if not data:
                raise ValueError("No data to export")
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            
            # Format the DataFrame
            formatted_df = self._format_dataframe(df)
            
            # Generate filename
            filename = self._clean_filename(question)
            file_path = os.path.join(self.temp_dir, filename)
            
            # Add metadata as comments if requested
            if include_metadata:
                metadata_lines = [
                    f"# Rounds Analytics Export",
                    f"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                    f"# Question: {question}",
                    f"# Records: {len(data)}",
                    f"#"
                ]
                
                # Write metadata and data
                with open(file_path, 'w', newline='', encoding='utf-8') as f:
                    # Write metadata as comments
                    for line in metadata_lines:
                        f.write(line + '\n')
                    
                    # Write CSV data
                    formatted_df.to_csv(f, index=False)
            else:
                # Write CSV directly
                formatted_df.to_csv(file_path, index=False)
            
            logger.info(f"Created CSV file: {filename} with {len(data)} records")
            return file_path, filename
            
        except Exception as e:
            logger.error(f"Error creating CSV file: {e}", exc_info=True)
            raise Exception(f"Failed to create CSV file: {str(e)}")
    
    async def create_excel_file(self, data: List[Dict[str, Any]], 
                              question: str, sql_query: str = "") -> Tuple[str, str]:
        """
        Create an Excel file from query results (future enhancement).
        
        Args:
            data: Query result data
            question: Original user question
            sql_query: SQL query used
            
        Returns:
            Tuple of (file_path, filename)
        """
        try:
            if not data:
                raise ValueError("No data to export")
            
            # Convert to DataFrame
            df = pd.DataFrame(data)
            formatted_df = self._format_dataframe(df)
            
            # Generate filename
            base_filename = self._clean_filename(question)
            filename = base_filename.replace('.csv', '.xlsx')
            file_path = os.path.join(self.temp_dir, filename)
            
            # Create Excel file with multiple sheets
            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                # Write main data
                formatted_df.to_excel(writer, sheet_name='Data', index=False)
                
                # Add metadata sheet
                self._add_metadata_sheet(writer, question, sql_query, len(data))
                
                # Auto-adjust column widths
                worksheet = writer.sheets['Data']
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
            
            logger.info(f"Created Excel file: {filename} with {len(data)} records")
            return file_path, filename
            
        except Exception as e:
            logger.error(f"Error creating Excel file: {e}", exc_info=True)
            raise Exception(f"Failed to create Excel file: {str(e)}")
    
    def validate_export_data(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Validate data before export and provide information about the data.
        
        Args:
            data: Query result data to validate
            
        Returns:
            Validation results and data information
        """
        try:
            if not data:
                return {
                    "is_valid": False,
                    "error": "No data to export",
                    "record_count": 0,
                    "column_count": 0
                }
            
            # Convert to DataFrame for analysis
            df = pd.DataFrame(data)
            
            # Check for basic issues
            issues = []
            
            # Check for completely empty columns
            empty_columns = df.columns[df.isnull().all()].tolist()
            if empty_columns:
                issues.append(f"Empty columns found: {empty_columns}")
            
            # Check for very wide data (too many columns)
            if len(df.columns) > 50:
                issues.append(f"Large number of columns ({len(df.columns)}) may affect readability")
            
            # Check for very long data
            if len(df) > 10000:
                issues.append(f"Large dataset ({len(df)} rows) may take time to process")
            
            # Estimate file size
            estimated_size_mb = (df.memory_usage(deep=True).sum() / 1024 / 1024)
            
            return {
                "is_valid": True,
                "issues": issues,
                "record_count": len(df),
                "column_count": len(df.columns),
                "estimated_size_mb": round(estimated_size_mb, 2),
                "columns": df.columns.tolist(),
                "data_types": df.dtypes.to_dict()
            }
            
        except Exception as e:
            return {
                "is_valid": False,
                "error": f"Validation error: {str(e)}",
                "record_count": 0,
                "column_count": 0
            }
    
    def cleanup_temp_files(self, max_age_hours: int = 24):
        """
        Clean up old temporary CSV files.
        
        Args:
            max_age_hours: Maximum age of files to keep (in hours)
        """
        try:
            current_time = datetime.now()
            cutoff_time = current_time.timestamp() - (max_age_hours * 3600)
            
            cleaned_count = 0
            
            for filename in os.listdir(self.temp_dir):
                if filename.startswith('rounds_analytics_') and filename.endswith('.csv'):
                    file_path = os.path.join(self.temp_dir, filename)
                    
                    try:
                        file_mtime = os.path.getmtime(file_path)
                        if file_mtime < cutoff_time:
                            os.unlink(file_path)
                            cleaned_count += 1
                    except OSError:
                        continue
            
            if cleaned_count > 0:
                logger.info(f"Cleaned up {cleaned_count} old CSV files")
                
        except Exception as e:
            logger.error(f"Error cleaning up temp files: {e}", exc_info=True) 